{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter03_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkGijHqW/lkoHCLcyCOhO2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonhyuncheol/AI/blob/master/foundation/chapter03_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twvdsdTu1r5M"
      },
      "source": [
        "# **회귀(Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXCitBIZ3lFx"
      },
      "source": [
        "지도 학습 알고리즘은 크게 분류와 회귀로 나뉜다.\n",
        "\n",
        "---\n",
        "\n",
        "분류는 샘플을 몇 개의 클래스 중 하나로 분류하는 문제였다.\n",
        "\n",
        "회귀는 임의의 숫자를 예측하는 문제로 정해진 클래스가 없고 임의의 수치를 출력한다.\n",
        "\n",
        "---\n",
        "\n",
        "이진분류에서는 타깃이 양성 클래스는 1, 음성 클래스는 0이었다.\n",
        "\n",
        "회귀에서는 타깃이 임의의 숫자이다.\n",
        "\n",
        "예를 들어서 농어의 무게를 예측한다고 하면 타깃은 농어의 무게가 되는 것이다.\n",
        "\n",
        "즉, 예측하고자 하는 대상이 타깃이 된다,\n",
        "\n",
        "---\n",
        "\n",
        "분류에서는 타깃을 직접 만들어서 사용했다.\n",
        "\n",
        "회귀에서는 타깃은 실제 데이터이다. \n",
        "\n",
        "그래서 이진분류와 다르게 타깃을 만들 필요가 없고, 훈련 데이터에 있는 열 중에 하나가 타깃 값이 된다. 즉, 어떤 특성값이 타깃이 되는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJok5nVZ5HqU"
      },
      "source": [
        "회귀라는 용어는 19세기 통계학자이나 사회학자인 프랜시스 골턴(Francis Galton)이 처음 사용했다.\n",
        "\n",
        "그가 쓴 논문에 키가 큰 사람의 아이가 부모보다 더 크지 않는다는 사실을 관찰하고 이를 평균으로 회귀한다라고 표현했다.\n",
        "\n",
        "그 후 두 변수 사이의 상관관계를 분석하는 방법을 회귀라 불렀다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rauj8FBn4z6t"
      },
      "source": [
        "# **k-최근접 이웃 회귀**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqbd-oVx5pJa"
      },
      "source": [
        "k-최근접 이웃 분류는 가장 가까운 샘플 k개를 선택하고, 이 샘플들의 클래스를 확인하여 다수 클래스를 새로운 샘플의 클래스로 예측했다.\n",
        "\n",
        "---\n",
        "\n",
        "k-최근접 이웃 회귀도 가장 가까운 샘플 k개를 선택한다.\n",
        "\n",
        "회귀는 분류와 다르게 이웃한 샘플의 타깃값, 임의의 수치들의 평균을 구하면된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWPiZ05_6_G5"
      },
      "source": [
        "# **데이터 준비**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te56Rvgv63Y4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "perch_length = np.array(\n",
        "    [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, \n",
        "     21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, \n",
        "     22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, \n",
        "     27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, \n",
        "     36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, \n",
        "     40.0, 42.0, 43.0, 43.0, 43.5, 44.0]\n",
        "     )\n",
        "\n",
        "perch_weight = np.array(\n",
        "    [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, \n",
        "     110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, \n",
        "     130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, \n",
        "     197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, \n",
        "     514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, \n",
        "     820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, \n",
        "     1000.0, 1000.0]\n",
        "     )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "1vMDY_Fl663g",
        "outputId": "c818720d-d5cd-444b-caf2-fab6da41a9ae"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(perch_length, perch_weight)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbRklEQVR4nO3df5CcdZ3g8feHMOog6KDkEAa4UErFUliJjMpe9rYUToI/FrLoorvqopsrdqv0FnUvS7CsQ/e8I5pVZOu2qENQsWQVQS6wam3kSCjvPOVMSDAKpmQVJCNCXBhklzkYwuf+6KdDz6R7np6Z7n66Z96vqq7p5/s83f3hKdKf/v6OzESSpNkcUnUAkqT+Z7KQJJUyWUiSSpksJEmlTBaSpFKHVh1ANxx11FG5YsWKqsOQpIGyY8eOX2fm8mbnFmWyWLFiBdu3b686DEkaKBFxf6tzNkNJkkqZLCRJpUwWkqRSJgtJUimThSSp1KIcDSVJg2TzznE2bdnDLycmOXZkmPVrVrJ21Wjb53vBZCFJFdq8c5xLbtrN5NR+AMYnJrnkpt0ArF01Wnq+V2yGkqQKbdqy50AiqJuc2s+mLXvaOt8rJgtJqtAvJyZnLS873ysmC0mq0LEjw7OWl53vFZOFJFVo/ZqVDA8tm1Y2PLSM9WtWtnW+V+zglqQK1TupW412KjvfK7EY9+AeGxtLFxKUpLmJiB2ZOdbsnM1QkqRSJgtJUimThSSplMlCklTKZCFJKmWykCSVMllIkkqZLCRJpZzBLUkL0A97TfSCyUKS5qlf9proha4li4j4PPBW4OHMPLkoexFwPbACuA84PzMfjYgArgDeDDwBvDcz7yxecwHw0eJtP5GZ13YrZkmai9n2muhksmhWe6l/fr3sDS9fzraf7OtaDaebNYsvAv8N+FJD2QbgtszcGBEbiuOLgTcBJxWP1wFXAq8rksulwBiQwI6IuCUzH+1i3JLUll7sNdGs9rL+hrsgYGp/Hij78vd/ceA13ajhdK2DOzO/Azwyo/hcoF4zuBZY21D+paz5PjASEccAa4BbM/ORIkHcCpzdrZglaS56sddEs9rL1DN5IFG00und9Ho9GurozHyweP4r4Oji+SjwQMN1e4uyVuUHiYgLI2J7RGzft29fZ6OWpCZ6sdfEQmopnazhVDZ0Nmtro3dsffTMvCozxzJzbPny5Z16W0lqae2qUS477xRGR4YJYHRkmMvOO6WjfQULqaV0sobT69FQD0XEMZn5YNHM9HBRPg4c33DdcUXZOPD6GeW39yBOSWrL2lWjXR35tH7Nyml9FgBDh8S0PotmOl3D6XXN4hbgguL5BcDNDeV/HDWnA48VzVVbgLMi4siIOBI4qyiTpCWhWe1l0x+8ik1vf9W0sneffkJXazjdHDr7FWq1gqMiYi+1UU0bga9FxDrgfuD84vJvURs2ey+1obPvA8jMRyLiPwM/KK77q8yc2WkuSYtaq9pLL+dyuK2qJAlwW1VJ0gKZLCRJpUwWkqRSJgtJUimThSSplMlCklTKZCFJKmWykCSVMllIkkq5raoktdDO/truwS1JS1g7+2svpT24bYaSpCZm2197LtcsFiYLSWqinf21e7EHd78wWUhSE+3sr92LPbj7hclCkppoZ3/tXuzB3S/s4JakJuod1LONdGrnmsXCzY8kSYCbH0mSFshmKElaACflSZJmtZQm5ZksJPWdQfm1PtukvH6MdyFMFpL6yiD9WndSniRVZJCW0HBSniRVZJB+rS+lSXkmC0l9pZ9+rW/eOc7qjVs5ccM3Wb1xK5t3jk87v3bVKG87bZRlEQAsi+Btp432XXNZJ5gsJPWVfvm1Xu87GZ+YJHm276QxYWzeOc7Xd4yzv5jcvD+Tr+8YPyipLAYmC0l9Ze2qUS477xRGR4YJYHRkmMvOO6Xnv9Zdony6SkZDRcSHgH8PJLAbeB9wDPBV4MXADuA9mflURDwX+BJwGvBPwDsy874q4pbUG2tXVd+U4xLl0/W8ZhERo8CfA2OZeTKwDHgn8Eng8sx8GfAosK54yTrg0aL88uI6SeoqlyifrqpmqEOB4Yg4FDgMeBA4A7ixOH8tsLZ4fm5xTHH+zIiiN0mSusQlyqfreTNUZo5HxF8DvwAmgW9Ta3aayMyni8v2AvU66CjwQPHapyPiMWpNVb9ufN+IuBC4EOCEE07o9n+GpEXOJcqn63myiIgjqdUWTgQmgBuAsxf6vpl5FXAV1JYoX+j7SVI7fSf90L/SC1U0Q/074OeZuS8zp4CbgNXASNEsBXAcUB97Ng4cD1CcfyG1jm5JUo9UkSx+AZweEYcVfQ9nAncD24C3F9dcANxcPL+lOKY4vzUX445NktTHep4sMvMOah3Vd1IbNnsIteaji4EPR8S91Pokrilecg3w4qL8w8CGXscsSUud26pKkgC3VZUkLZDJQpJUymQhSSplspAklTJZSJJKmSwkSaVMFpKkUiYLSVIpk4UkqZTJQpJUqpJtVSVpoTbvHJ91H4my85obk4WkgbN55ziX3LSbyan9AIxPTHLJTbuB2v4Sm3eOs/6Gu5h6Jg+cX3/DXQfOa+5cSFDSwFm9cSvjE5MHlS+L4JniO63ZN9vI8BC7Lj2ry9ENrtkWErRmIWng/LJJogDYX/Ljd2JyqhvhLAl2cEsaOMeODFcdwpJjspA0cNavWcnw0LI5v+7Iw4a6EM3SYDOUpIFT76Suj3Y6JKK0CWpoWXDp772yF+EtSiYLSQNp7arRA0lj5ugogKFDgsOfdygTT0w5dLYDTBaSBt7MmobJofNMFpIWhcaaRqc4se9ZJgtJaqJs4t9S42goSWpi05Y90/pAACan9rNpy56KIqqWyUKSmmg18a9V+WJnspCkJlpN/FuqEwJNFpLURLOJf8NDy1i/ZmVFEVWrrWQRERe1UyZJi8XaVaNcdt4pjI4ME8DoyDCXnXfKkuzchjZXnY2IOzPz1TPKdmbmqq5FtgCuOitJczfvVWcj4g+BPwJOjIhbGk4dATyygIBGgKuBk6mtJPwnwB7gemAFcB9wfmY+GhEBXAG8GXgCeG9m3jnfz5YkzV3ZPIv/AzwIHAV8uqH8ceCHC/jcK4B/yMy3R8RzgMOAjwC3ZebGiNgAbAAuBt4EnFQ8XgdcWfyVJPXIrMkiM+8H7gd+u1MfGBEvBH4XeG/xGU8BT0XEucDri8uuBW6nlizOBb6Utfay70fESEQck5kPdiomSdLs2u3gPi8ifhoRj0XEbyLi8Yj4zTw/80RgH/CFiNgZEVdHxPOBoxsSwK+Ao4vno8ADDa/fW5RJknqk3aGznwLOycwXZuYLMvOIzHzBPD/zUODVwJVFB/m/UGtyOqCoRcxpv9eIuDAitkfE9n379s0zNElSM+0mi4cy854OfeZeYG9m3lEc30gteTwUEccAFH8fLs6PA8c3vP64omyazLwqM8cyc2z58uUdClWSBOWjoc4rnm6PiOuBzcCT9fOZedNcPzAzfxURD0TEyszcA5wJ3F08LgA2Fn9vLl5yC/CBiPgqtY7tx+yvkKTeKhsN9XsNz58Azmo4TmDOyaLwH4DripFQPwPeR62W87WIWEetU/384tpvURs2e28Rw/vm+ZmSpHkqGw3VlS/mzNwFNJv4cWaTaxN4fzfikCS1p639LCLib5oUPwZsz8ybm5yTpLa5yVD/a7eD+3nAqcBPi8dvUetoXhcRn+1SbJKWgPomQ+MTkyTPbjK0eedB41hUoXZ3yvstYHVm7geIiCuB/wX8DrC7S7FJWgJm22TI2kX/aLdmcSRweMPx84EXFcnjyeYvkaRybjI0GNqtWXwK2BURtwNBbbmO/1rMvP6fXYpN0hJw7Mgw400Sw1LdZKhftVWzyMxrgH9DbZ7F/wB+JzOvzsx/ycz13QxQ0uLmJkODoWxS3ssz8ycRUd/Lor5G00si4iUuFS5poer9Eo6G6m9lzVAfBi5k+vLkdQmc0fGIJA2khQx/Xbtq1OTQ58om5V1Y/H1Db8KRNIjqw1/ro5rqw18Bk8Ai0e4S5YdFxEcj4qri+KSIeGt3Q5M0KGYb/qrFod2hs18AnqLWyQ21VV8/0ZWIJA0ch78ufu0mi5dm5qeAKYDMfILaEFpJajnM1eGvi0e7yeKpiBim2JAoIl6Kk/EkFRz+uvi1OynvUuAfgOMj4jpgNcUe2pLk8NfFL2orgJdcFPFl4IfAJLX9J+7IzF93ObZ5Gxsby+3bt1cdhiQNlIjYkZnNto9ou2ZxDfBvgTcCLwV2RsR3MvOKDsUoSepjbSWLzNwWEd8BXgO8Afgz4JWAyUKSloB2Nz+6jdpKs9+jtjT5azLz4W4GJknqH+2OhvohtXkWJ1Pb2+LkYnSUJGkJaLcZ6kMAEXEEtVFQXwBeAjy3a5FJkvpGu81QH6DWwX0acB/weWrNUZKkJaDd0VDPAz4D7MjMp7sYjySpD7XbDPXX3Q5EktS/2u3gliQtYSYLSVIpk4UkqZTJQpJUymQhSSpVWbKIiGURsTMivlEcnxgRd0TEvRFxfUQ8pyh/bnF8b3F+RVUxS9JSVWXN4iLgnobjTwKXZ+bLgEeBdUX5OuDRovzy4jpJUg9Vkiwi4jjgLcDVxXEAZwA3FpdcC6wtnp9bHFOcP7O4XpLUI1XVLD4L/CXwTHH8YmCiYXb4XqC+xdYo8ABAcf6x4vppIuLCiNgeEdv37dvXzdglacnpebKIiLcCD2fmjk6+b2ZelZljmTm2fPnyTr61JC157a4N1UmrgXMi4s3U1px6AbVNlEYi4tCi9nAcMF5cPw4cD+yNiEOBFwL/1PuwJWnp6nnNIjMvyczjMnMF8E5ga2a+C9gGvL247ALg5uL5LcUxxfmt2c7G4ZKkjumneRYXAx+OiHup9UlcU5RfA7y4KP8wsKGi+CRpyaqiGeqAzLwduL14/jPgtU2u+X/AH/Q0MEnSNP1Us5Ak9SmThSSplMlCklTKZCFJKmWykCSVqnQ0lKTe2bxznE1b9vDLiUmOHRlm/ZqVrF01Wv5CCZOFtCRs3jnOJTftZnJqPwDjE5NcctNuABOG2mIzlLQEbNqy50CiqJuc2s+mLXsqikiDxmQhLQG/nJicU7k0k81QUh+Za79Cu9cfOzLMeJPEcOzIcEfj1+JlzULqE/V+hfGJSZJn+xU27xxf8PXr16xkeGjZtLLhoWWsX7OyC/8lWoxMFlKfmGu/wlyuX7tqlMvOO4XRkWECGB0Z5rLzTrFzW22zGUrqE3PtV5hr+dpVoyYHzZs1C6lPtOo/6FS5tBAmC6lPzLVfwX4I9ZLNUFKfqDcRbdqyh/GJSZZFTOuDmNmE1Hi9s7LVbSYLqY/Uv+jX33gXU/truwePT0yy/sa7pp1vvN7koF6wGUrqMx//+x8fSBR1U/uTj//9jyuKSDJZSH3n0SemWpafuOGbrN64teXcC6lbTBbSAGlnsp7UDSYLqc9ElF/jIoDqNZOF1Gcyy68BFwFUbzkaSppFFRsGjbZY9G8mJ9+pl6xZSC3MdWG/Tmk22W4mJ9+p10wWUgvd2jBo885xVm/c2nJkU7NF/959+gkuAqhK2QwltdCNDYPa3d7UyXbqN9YspBa6sVCf25tqUPU8WUTE8RGxLSLujogfR8RFRfmLIuLWiPhp8ffIojwi4m8i4t6I+GFEvLrXMWtpWshCfa2amtzeVIOqimaop4G/yMw7I+IIYEdE3Aq8F7gtMzdGxAZgA3Ax8CbgpOLxOuDK4q/UVfNdqG+2pia3N9Wg6nmyyMwHgQeL549HxD3AKHAu8PrismuB26kli3OBL2VmAt+PiJGIOKZ4H6mrmvUdlA2nna2paf2aldMSCTiySYOh0g7uiFgBrALuAI5uSAC/Ao4uno8CDzS8bG9RNi1ZRMSFwIUAJ5xwQtdi1tLWrNbwoet38cHrdzFaJI7ZmppcVlyDqrJkERGHA18HPpiZv4mGNQ4yMyOizXmsB15zFXAVwNjY2JxeK7WrWa2h/j9bvblp5LChposB1puaHOmkQVRJsoiIIWqJ4rrMvKkofqjevBQRxwAPF+XjwPENLz+uKJM6rqyJqawjenJqP8899BCGh5bZ1KRFpYrRUAFcA9yTmZ9pOHULcEHx/ALg5obyPy5GRZ0OPGZ/hbqhnRnb7XREPzY5ddCkOifRadBVUbNYDbwH2B0Ru4qyjwAbga9FxDrgfuD84ty3gDcD9wJPAO/rbbhaKmbrmD6wg12TDuqZjh0ZtqlJi04Vo6H+N9BqEeYzm1yfwPu7GpREe3MgZu6THTzbZwE2N2nxcrkPLRkz+yPe8PLlbPvJvgPHZR3TdY21hipWpZWqENnu4vkDZGxsLLdv3151GOojM4e8NjN0SEAwbf/roUOCw593KBNPTJkMtOhFxI7MHGt2zrWhtCQ064+YaeqZ5PnPOfRAx/TI8BBEbe9rtzPVUmczlAZeq6agj27ezVfueID9c6g9PzY5xa5LzwJg9catTExOb5aa2eEtLRUmCw2keoKY2clc//V/w/Zf8N1/fGTO79vYP+Gif9KzbIbSwGmcDwHTRyNB7df/fBLFzJFM3ViiXBpUJgsNnHb6H+bqyMOGDpo4t5AlyqXFxmYoDZxmS3zP17IIPn3+q5r2Qbjon/Qsk4UGziEBz8zSZz1zXabZritbhsOZ2FKNzVDquFa7xHXKbImivg7TbFyvSZo7axbqqNl2ievFF/N3N5wBwAev39Xymp9vfEvX45AWG2sW6qjZFuPrlJHhodLy0RYjllqVS5qdNQt11HznJpSt29TYsfyxc17J+hvuYuqZ6ctyfOycVx44dvtSqbNMFuqoY0eGm45WOnZkeNpEumUR7M9ktEgMX98xPq3p6svf/8WB185sympnlJIjmaTOciFBzVuzZTaApr/o33ba6LSE0GjmMt+tjI4MH+iTkNR5LiSojmu1qxzQdJe4bT/Z13I4a7s/V1xmQ6qOzVCal9k6sr+74YyDmns+NMvopHa5zIZUHWsWmpe5dmSXfdG32jqxzs5pqVomCx2knUl1c11kr9k6S3XDQ8t41+knTGu6eveMYyfQSdWyGUrTtDupbq5DU2fuXd04GspRSlL/M1ksIe3sFz1bX8RCh6a6zpI0uEwWA66dBFC/rp0aw1z6Ivzyl5YO+ywGWKvhq836GNpdhsMNfyQ1Y7IYYHNZh6ndGoMb/khqxmQxwObSZNRujWHtqtGmk+psbpKWNvssBths6zDNNJfRS/ZFSJrJmkWDbm/a02lzaTKyxiBpIQamZhERZwNXAMuAqzNzYyffv+pNe+ZjrsNXrTFImq+BSBYRsQz4W+CNwF7gBxFxS2be3anPaHd+Qb8xAUjqhUFphnotcG9m/iwznwK+CpzbyQ+Y76Y9krQUDEqyGAUeaDjeW5QdEBEXRsT2iNi+b9++OX+A8wskqbVBSRalMvOqzBzLzLHly5fP+fXOL5Ck1gaizwIYB45vOD6uKOsYt+GUpNYGJVn8ADgpIk6kliTeCfxRpz/EzmJJam4gkkVmPh0RHwC2UBs6+/nM/HHFYUnSkjEQyQIgM78FfKvqOCRpKVo0HdySpO4xWUiSSpksJEmlIjOrjqHjImIfcH+PP/Yo4Nc9/sz5MtbOG5Q4wVi7ZVBinS3Of52ZTSeqLcpkUYWI2J6ZY1XH0Q5j7bxBiROMtVsGJdb5xmkzlCSplMlCklTKZNE5V1UdwBwYa+cNSpxgrN0yKLHOK077LCRJpaxZSJJKmSwkSaVMFvMQEZ+PiIcj4kcNZS+KiFsj4qfF3yOrjLGuRawfi4jxiNhVPN5cZYxFTMdHxLaIuDsifhwRFxXlfXdfZ4m1H+/r8yLi/0bEXUWsHy/KT4yIOyLi3oi4PiKe06dxfjEift5wT0+tMs5GEbEsInZGxDeK4766p42axDrn+2qymJ8vAmfPKNsA3JaZJwG3Fcf94IscHCvA5Zl5avHohwUanwb+IjNfAZwOvD8iXkF/3tdWsUL/3dcngTMy81XAqcDZEXE68Elqsb4MeBRYV2GM0DpOgPUN93RXdSEe5CLgnobjfrunjWbGCnO8ryaLecjM7wCPzCg+F7i2eH4tsLanQbXQIta+k5kPZuadxfPHqf2PPUof3tdZYu07WfPPxeFQ8UjgDODGorzy+zpLnH0pIo4D3gJcXRwHfXZP62bGOl8mi845OjMfLJ7/Cji6ymDa8IGI+GHRTFV5006jiFgBrALuoM/v64xYoQ/va9EEsQt4GLgV+EdgIjOfLi45aE/7KsyMMzPr9/S/FPf08oh4boUhNvos8JfAM8Xxi+nDe1qYGWvdnO6ryaILsjYeuW9/FQFXAi+lVt1/EPh0teE8KyIOB74OfDAzf9N4rt/ua5NY+/K+Zub+zDyV2nbErwVeXnFITc2MMyJOBi6hFu9rgBcBF1cYIgAR8Vbg4czcUXUsZWaJdc731WTROQ9FxDEAxd+HK46npcx8qPiH+QzwOWpfIJWLiCFqX77XZeZNRXFf3tdmsfbrfa3LzAlgG/DbwEhE1Dc/6/ie9gvREOfZRZNfZuaTwBfoj3u6GjgnIu4Dvkqt+ekK+vOeHhRrRHx5PvfVZNE5twAXFM8vAG6uMJZZ1b98C78P/KjVtb1StPleA9yTmZ9pONV397VVrH16X5dHxEjxfBh4I7U+lm3A24vLKr+vLeL8ScMPhaDWB1D5Pc3MSzLzuMxcAbwT2JqZ76LP7im0jPXd87mvA7Otaj+JiK8ArweOioi9wKXARuBrEbGO2vLo51cX4bNaxPr6YqhcAvcBf1pZgM9aDbwH2F20WwN8hP68r61i/cM+vK/HANdGxDJqPw6/lpnfiIi7ga9GxCeAndSSX5Vaxbk1IpYDAewC/qzKIEtcTH/d09lcN9f76nIfkqRSNkNJkkqZLCRJpUwWkqRSJgtJUimThSSplMlCmoeI+Ofyq+b8nqc2rlRbrGL7Hzv9OdJ8mCyk/nEqUPmy5lIzJgtpgSJifUT8oFiUrb4Pw4qIuCciPlfsz/DtYmYyEfGa4tpdEbEpIn5U7H3wV8A7ivJ3FG//ioi4PSJ+FhF/XtF/omSykBYiIs4CTqK2ts6pwGkR8bvF6ZOAv83MVwITwNuK8i8Af1osmrcfIDOfAv4TcH2xv8D1xbUvB9YU739psSaV1HMmC2lhzioeO4E7qX25n1Sc+3nDpjI7gBXF+kdHZOb3ivK/K3n/b2bmk5n5a2qLKPbVEu1aOlwbSlqYAC7LzP8+rbC2z8WTDUX7geF5vP/M9/DfrCphzUJamC3AnxR7WxARoxHxr1pdXCy//XhEvK4oemfD6ceBI7oWqbQAJgtpATLz29Sakr4XEbupbatZ9oW/DvhcsWLt84HHivJt1Dq0Gzu4pb7gqrNSj0XE4fX9piNiA3BMZl5UcVjSrGz/lHrvLRFxCbV/f/cD7602HKmcNQtJUin7LCRJpUwWkqRSJgtJUimThSSplMlCklTq/wPl5yBP2W4mzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjQ-dAUp7-V_"
      },
      "source": [
        "우리는 농어의 길이를 보고, 농어의 무게를 예측할 것이다.\n",
        "\n",
        "그러므로 농어의 길이는 특성이고, 무게는 타깃이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SggF4aaT8yG2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS1FeFjPBOIT"
      },
      "source": [
        "사이킷런의 train_test_split() 함수를 사용해 훈련 세트와 테스트 세트로 나눈다.\n",
        "\n",
        "이전에는 train_test_split() 함수에 stratify 매개변수에 타깃 데이터를 전달해서 클래스 비율에 맞게 골고루 섞었다.\n",
        "\n",
        "하지만 이번에는 분류 문제가 아닌 회귀 문제이고, 임의의 숫자가 타깃이기 때문에 사용하지 않는다.\n",
        "\n",
        "보통 회귀에서는 랜덤으로 섞어서 훈련 세트와 테스트 세트로 나누는 것이 일반적이다.\n",
        "\n",
        "---\n",
        "\n",
        "train_test_split() 함수에 perch_length를 전달하면 두 리스트는 1차원 배열이기 때문에 이를 나눠서 나온 train_input과 test_input도 1차원 배열로 결과가 나온다.\n",
        "\n",
        "사이킷런의 모델들은 입력 데이터가 행 방향으로 샘플이 있고, 열 방향으로 특성이 있는 2차원 배열이라고 기대하고 있다.\n",
        "\n",
        "이번 예제에서는 특성을 1개만 사용하므로 1개의 열이 있는 2차원 배열로 바꿔야한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvOINLXgDb8H"
      },
      "source": [
        "train_input = train_input.reshape(-1, 1)\n",
        "test_input = test_input.reshape(-1, 1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26a5vBzYDsh6"
      },
      "source": [
        "배열의 모양을 바꿀 때, 크기를 바꿀 때 넘파이의 reshape() 메소드를 사용하면 된다.\n",
        "\n",
        "첫 번째 행 차원을 -1로 지정하고, 두 번째 열 차원을 1로 지정했다.\n",
        "\n",
        "---\n",
        "\n",
        "행 차원을 -1로 지정하면 차원이 모두 결정되고, 남은 차원을 모두 행에 채운다.\n",
        "\n",
        "열 차원을 1로 지정하면 하나의 열이 있는 배열이 만들어 진다.\n",
        "\n",
        "reshape(-1, 1)과 같이 사용하면 배열의 전체 원소 개수를 매번 외우지 않아도 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnEqLmqDKnhX"
      },
      "source": [
        "# **회귀 모델 훈련**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itXdIwkYKSKG",
        "outputId": "8e326eef-b4ee-49fb-a58d-782699be7178"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knr = KNeighborsRegressor()\n",
        "\n",
        "knr.fit(train_input, train_target)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW3bDHvwKUQz",
        "outputId": "f8bdd6d4-8356-42b0-80ec-d4fd09427c49"
      },
      "source": [
        "knr.score(test_input, test_target)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9928094061010639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpfvRghiKYU1"
      },
      "source": [
        "사이키런에서 k-최근접 이웃 회귀 알고리즘을 구현한 클래스는 KNeighborsRegressor이다.\n",
        "\n",
        "KNeighborsClassifier와 비슷하게 객체를 생성하고 fit()메소드로 모델을 훈련한다.\n",
        "\n",
        "그리고 score()메소드로 테스트 세트를 전달해서 평가한다.\n",
        "\n",
        "---\n",
        "\n",
        "분류 문제에서는 테스트 세트에 있는 샘플을 정확하게 분류한 개수의 비율, 즉, 정확도가 나왔다.\n",
        "\n",
        "회귀 문제에서는 예측하는 값이나 타깃 모두 임의의 수치이기 때문에 정확한 숫자를 맞힌다는 것은 거의 불가능하다.\n",
        "\n",
        "그래서 회귀 문제에서는 정확도대신 R^2(결정계수)라는 값이 나온다.\n",
        "\n",
        "결정 계수의 계산 방식은 각 샘플의 타깃과 예측한 값의 차이를 제곱하여 더한다.\n",
        "\n",
        "그 다음 타깃과 타깃 평균의 차이를 제곱하여 더한 값으로 나눈다.\n",
        "\n",
        "마지막으로 1로 뺀다.\n",
        "\n",
        "**R^2 = 1 - (타깃-예측)^2의 합 / (타깃-타깃평균)^2의 합**\n",
        "\n",
        "---\n",
        "\n",
        "만약 예측이 평균 정도라면 분모와 분자가 비슷해질 것이다. 그러면 결정 계수는 0에 가까운 값이 된다.\n",
        "\n",
        "만약 예측이 타깃 정도라면 분자가 0에 가까워질 것이다. 그러면 결정 계수는 1에 가까운 값이 된다.\n",
        "\n",
        "그래서 R^2는 0 ~ 1 사이의 값이 나온다.\n",
        "\n",
        "R^2가 1에 가까울 수록 좋은 모델이고, 0에 가까울 수록 나쁜 모델이라고 판단한다.\n",
        "\n",
        "---\n",
        "\n",
        "※여기서 잠깐※\n",
        "\n",
        "사이킷런의 score() 메소드가 출력하는 값은 높을 수록 좋은 것이다. 정확도나 결정계수도 마찬가지이다.\n",
        "\n",
        "만약 score() 메소드가 에러율을 반환한다면 이를 음수로 만들어 실제로는 낮은 에러가 score() 메소드로 반환될 때는 높은 값이 되도록 바꾼다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1VVPKFTTOnB",
        "outputId": "0c3f0a60-10b4-4bd4-e320-2364eab9747f"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 테스트 세트에 대한 예측을 만듭니다\n",
        "test_prediction = knr.predict(test_input)\n",
        "\n",
        "# 테스트 세트에 대한 평균 절댓값 오차를 계산합니다\n",
        "mae = mean_absolute_error(test_target, test_prediction)\n",
        "\n",
        "print(mae)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19.157142857142862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqeGf-FJTaJv"
      },
      "source": [
        "R^2(결정계수)말고도 다른 지표를 사용해서 모델을 성능을 평가할 수 있다.\n",
        "\n",
        "특히 회귀모델같은 경우는 평균절대값오차(MAE) 혹은 평균제곱근오차(MSE)를 사용한다.\n",
        "\n",
        "여기서는 MAE를 사용해보겠다.\n",
        "\n",
        "---\n",
        "\n",
        "특정 지표들은 사이킷런의 metrics 모듈 하위에 있다.\n",
        "\n",
        "MAE는 사이킷런의 metrics 모듈 하위에 mean_absolute_error() 함수를 사용하면 된다.\n",
        "\n",
        "mean_absolute_error() 함수에 첫 번째 매개변수로 테스트 세트의 target값과 두 번째 매개변수로 테스트 세트의 input으로 예측한 값을 전달하면된다.\n",
        "\n",
        "mean_absolute_error는 타깃과 예측의 절대값 오차를 평균하여 반환한다.\n",
        "\n",
        "---\n",
        "\n",
        "결과로 약 19가 나왔다.\n",
        "\n",
        "농어의 무게를 이 모델이 예측했는데 예측이 평균적으로 19g 정도 타깃값과 다르다, 오차가 난다는 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2pufL8LYFES"
      },
      "source": [
        "# **과대적합(Overfitting)과 과소적합(Underfitting)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tZ_SfKhYUcY"
      },
      "source": [
        "지금까지 훈련 세트를 사용해 모델을 훈련하고 테스트 세트로 모델을 평가했다.\n",
        "\n",
        "맨 처음에는 훈련 세트로 평가를 했었다. 하지만 그 방법은 옳지 않은 평가 방법이라고 하고, 테스트 세트로 평가를 했다.\n",
        "\n",
        "이번에는 훈련 세트와 테스트 세트 두 개 다 사용해서 평가해서 두 개를 다 사용했을 때 어떤 insight가 나올지 확인해보겠다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i7zBgLKYK3z",
        "outputId": "8ceeeda7-39a6-4201-9092-7840944be4ec"
      },
      "source": [
        "print(knr.score(train_input, train_target))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9698823289099255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI-SUBeXYQGJ",
        "outputId": "f174a731-a7f6-4048-ad81-601e57bae366"
      },
      "source": [
        "knr.score(test_input, test_target)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9928094061010639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlDE1PXBYVHt"
      },
      "source": [
        "머신러닝에서 훈련 세트와 테스트 세트로 적절하게 준비했다면 일반적으로 훈련 세트의 점수가 테스트 세트보다 높아야한다.\n",
        "\n",
        "당연히 훈련 세트에서 모델을 훈련했으므로 훈련 세트에서 더 좋은 점수가 나와야한다.\n",
        "\n",
        "하지만 테스트 세트의 점수가 더 높게 나왔다.\n",
        "\n",
        "이런 현상을 훈련 세트를 적절히 학습하지 못했다. 과소적합되었다.라고 한다.\n",
        "\n",
        "---\n",
        "\n",
        "훈련 세트에서 점수가 높았지만 테스트 세트에서 점수가 낮다면 모델이 훈련 세트에 과대적합(overfitting)되었다고 말한다.\n",
        "\n",
        "즉, 훈련 세트에만 잘 맞는 모델이라 테스트 세트나 나중에 실전에 투입하여 새로운 샘플에 대한 예측을 만들 때 잘 동작하지 않을 것이다.\n",
        "\n",
        "훈련 세트보다 테스트 세트의 점수가 높거나 두 점수가 모두 낮다면 모델이 훈련 세트에 과소적합(underfitting)되었다고 말한다.\n",
        "\n",
        "즉, 모델이 너무 단순하여 훈련 세트에 적절히 훈련되지 않은 경우이다.\n",
        "\n",
        "---\n",
        "\n",
        "※ 여기서 잠깐 ※\n",
        "\n",
        "과소적합이 일어나는 또 다른 이유는 훈련 세트와 테스트 세트의 크기가 매우 작기 때문이다.\n",
        "\n",
        "데이터가 작으면 테스트 세트가 훈련 세트의 특징을 따르지 못할 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi4rVQ5QiwYz",
        "outputId": "7cf619e8-ad46-4947-8476-ecb6fbe93972"
      },
      "source": [
        "# 이웃의 갯수를 3으로 설정합니다\n",
        "knr.n_neighbors = 3\n",
        "\n",
        "# 모델을 다시 훈련합니다\n",
        "knr.fit(train_input, train_target)\n",
        "print(knr.score(train_input, train_target))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9804899950518966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkHCzuwDi22Y"
      },
      "source": [
        "과소적합을 해결하기 위해서는 모델을 복잡하게 만들면 된다.\n",
        "\n",
        "즉 훈련 세트에 더 잘 맞게 모델을 만들면 테스트 세트의 점수는 낮아질 것이다.\n",
        "\n",
        "k-최근접 이웃 알고리즘으로 모델을 복잡하게 만드는 방법은 이웃의 개수 k를 줄이는 것이다.\n",
        "\n",
        "---\n",
        "\n",
        "k-최근접 이웃 알고리즘에서 k의 개수가 커지면 과소적합 k의 개수가 작아지면 \n",
        "과대적합이 일어난다.\n",
        "\n",
        "이웃의 개수를 줄이면 훈련 세트에 있는 국지적인 패턴에 민감해지고, 이웃의 개수를 늘리면 데이터 전반에 있는 일반적인 패턴을 따를 것이다.\n",
        "\n",
        "예를 들어서 k를 1로 지정하면 가까운 이웃 하나만 고려하기 때문에 훈련 세트의 전체적인 경향을 따르지 못하고, 샘플 하나하나에 따라가는 들쭉날쭉한 예측을 만들어낸다.\n",
        "\n",
        "---\n",
        "\n",
        "이전에 설명한 것처럼 사이킷런의 k-최근접 이웃 클래스는 이웃의 개수를 바꾸는 방법려면 n_neighbors 속성값을 바꾸면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r55HmQI7i3E-",
        "outputId": "e45054fc-ef33-44b0-c233-09c7f20f7fb7"
      },
      "source": [
        "print(knr.score(test_input, test_target))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.974645996398761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60llkY2olmnZ"
      },
      "source": [
        "테스트 세트의 점수가 훈련 세트보다 낮아졌으므로 과소적합 문제를 해결하였다.\n",
        "\n",
        "---\n",
        "\n",
        "최적의 k값은 문제마다 변화한다. 최적의 k값을 찾는 방법은 다음에 알아보겠다.\n",
        "\n",
        "이런 k값 같은 우리가 지정해야하는 매개변수를 하이퍼파라미터라고 한다.\n",
        "\n",
        "하이퍼파라미터는 클래스나 함수의 매개변수로 지정할 수 있게 끔 되어있다."
      ]
    }
  ]
}
